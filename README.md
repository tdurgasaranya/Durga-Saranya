# Portfolio
![img](https://www.hostinger.com/tutorials/wp-content/uploads/sites/2/2022/04/web-developer-portfolio.png)


# My Project works - Data Analytics

[Professional Summary LinkedIn Profile](https://www.linkedin.com/in/durga-saranya-t-886a47146/)

## Introduction
In this Portfolio document, I would like to share my work details on the projects I have worked and have been working on data analytics. These projects aim to leverage data-driven insights and advanced analytics techniques to solve real time Organizations data problems and driving meaningful impact. Below, I outline the key details and objectives of my projects.

## Projects Description

**Project1 - Supply chain Master data analysis and reporting**

[Project1 link: Micron Technology](https://www.micron.com/about/our-commitment/sourcing-responsibly/supply-chain)

- Extracting data from various sources and performing ETL Process to load the data on to SQL Server
- With the data on SQL Server helped cross functional teams to do data manupulations and transformations to generate results.
- Managed and maintained production data on supply chain domain and helped to build a data pipelines for reporting.
- Visualized the data on Tableau in intuitive and interactive ways to help end users understand the statistics of data and make decisions.

**Project2 - Reporting solutions in Live data for Coral Reef bleaching issue**

[Project2 link: CIS_671](https://coralreefwatch.noaa.gov/satellite/research/coral_bleaching_report.php)

- Extracting data from excel public source and performing ETL Process to load the data on to SQL Server
- With the data on SQL Server helped cross functional teams to transform the data using SQL and did data manupulations.
- Developed the graphs on Tableau that would predict the trends and behavious of corals location wise.
- Identified the factors like High heat, climatic conditions influencing the corals getting more bleached and provided the statistics.
- Visualized the data on Tableau in intuitive and interactive ways to help end users understand the statistics of data and make decisions.


**Project3 - Database management solutions for GVSU Science-Inventory management data**

[Project3 link: GVSU_CSIMS](https://www.gvsu.edu/clas/labresource/chemical-and-supply-information-management-system-70-60.htm)

- Worked on the Filemaker pro (Claris) tool to maintain and manage the database for the inventory system in GVSU.
- Created filemaker objects and layouts for the end users and created interactive applets, UI on filemaker with backened database design and  modeling the schema.
- Organized and managed the database structures and handled the documentations.

# Current Project in my Internship ~ Dream Job

**Project4: Data analytics and Reporting solutions to Marmon Food Service & Technologies**

[Project4 link: FoodService production data](https://www.marmon.com/business-groups/foodservice-technologies/)

- Creating Adhoc reports and developing reporting solutions using analytical tools like SQL Server and PowerBI.
- Data Organizing and collection / extraction of data from LN Infor site and performing data transformations on sql server.
- Creating models for predicting factors impacting in supply chain and by visualizing results explaining the statistics of data.'
- Database management and developing reporting solutions to the end user or clients.

# Dream project to work:

[NASA Data analytics:](https://www.nas.nasa.gov/supercomputing/data_analytics.html)


- I would like to work on NASA data and help solving real time space statistics and to provide reporting solutions for scientific related data.
- I worked on diverse domains and various areas of data like Supply chain, Production , Manufacturing, Food processing, Services and other so My dream project would be trying out real time data analysis on NASA space/scientific data.
  

# ***Current Project POC***:

- Providing Automated reporting solutions to client with less manual interaction
- Automated solution in power Bi reporting that is achieved with Python scripting with SQL integration.
- Python scripts are widely used for automating load jobs for scheduled executions and automated transformations, data manupulations on SQL server that end up data loading on to reporting tools like Power Bi.


## Work Flow I follow for the Projects:

The primary objectives of my projects are as follows:

1. **Data Collection**: TO gather relevant data from various sources, ensuring its quality and integrity.

2. **Data Exploration and Preprocessing**: To Perform exploratory data analysis to gain insights into the data. Clean, transform, and preprocess the data as needed to ensure its suitability for analysis.

3. **Feature Engineering**: New featuring to enhance the predictive power of the models.

4. **Model Development**: To develop robust and accurate predictive models using suitable machine learning or statistical techniques.

5. **Model Evaluation and Selection**: Evaluating the performance of different models and select the most appropriate one based on predefined criteria.
6. **Insights and Recommendations**: Derive actionable insights from the data analysis results and provide recommendations to address the problem or optimize the desired outcomes.
7. **Visualization and Reporting**: Creating visually appealing and informative visualizations to effectively communicate the findings and insights to stakeholders.

## Tools and Technologies

To accomplish all the projects mentioned above, I utilize the following tools and technologies:

- Programming Languages: [Python, SQL]
- Data Analysis and Machine Learning Libraries: [Pandas, NumPy]
- Data Visualization Tools: [Tableau, PowerBi]
- Integrated Development Environment (IDE): [IDLE Python, PyCharm]
- Analytical Tools and softwares: [SQL Server, SSIS, InforLN, SAP HANA, Snowflake Cloud, Filemaker]
- Data Storage and Manipulation: [SQL, CSV, EXCELs, Sharepoint, Snowflake Cloud, Azure Data storage]
- Collaboration and Version Control: [JIRA, ServiceNow, GitHub, Git]

## Expected Impact

- **Improved Decision-Making**: The insights gained from data analytics will enable more informed and data-driven decision-making processes.

- **Efficiency and Optimization**: By identifying inefficiencies and bottlenecks, the project will drive optimization and process improvements.

- **Predictive Capabilities**: The developed predictive models will aid in forecasting future trends, enabling proactive measures to be taken.

- **Competitive Advantage**: Leveraging data analytics will provide a competitive edge, helping to differentiate and excel in the chosen domain.



# The Data solution I would like to work further for a competition is : 

[Predict H1N1 and Seasonal Flu Vaccines](https://www.drivendata.org/competitions/66/flu-shot-learning/)

- I had a over view of this scenario and like to work on a solution for this competition
- The key elements I analyzed are:
- Using a Machine learning approach we can provide a solution to this scarenio like :
- Creating a Model after data collection, pre processing and featuring selection of most impacting factors in prediction.
- **An efficient approach would be creating a ML Model like "Logistic Regression" can predict the results.**
  

# User related materials:

## Useful Beginner's Cheat Sheet - R Script
## Cheat Codes

### Data Manipulation

1. **Create a Vector**: `x <- c(1, 2, 3, 4, 5)`
2. **Access Elements in a Vector**: `x[3]` (accesses the third element)
3. **Create a Matrix**: `m <- matrix(1:9, nrow = 3, ncol = 3)`
4. **Access Elements in a Matrix**: `m[2, 3]` (accesses the element in the second row and third column)
5. **Create a Data Frame**: `df <- data.frame(x = c(1, 2, 3), y = c("a", "b", "c"))`
6. **Access Columns in a Data Frame**: `df$x` or `df[["x"]]`

### Data Analysis

1. **Summary Statistics**: `summary(x)` (provides summary statistics of a numeric vector)
2. **Calculate Mean**: `mean(x)`
3. **Calculate Standard Deviation**: `sd(x)`
4. **Calculate Correlation**: `cor(x, y)`
5. **Perform t-test**: `t.test(x, y)`
6. **Perform Chi-squared Test**: `chisq.test(x, y)`


## Video for a Regression example with realtime data

[Regression example like never expected!!!!!!](https://youtu.be/8JrcQ_j990U)


## Article and video suggestions on Supervised learning in statistical method


***source: MIT***

[Article Link by MIT](https://ailephant.com/tag/probabilities/)


[Video Link by MIT Professor](https://youtu.be/EC6bf8JCpDQ)


-  And finally "Supervised and Unsupervised learning Memes" :P
  

![Img](https://editor.analyticsvidhya.com/uploads/25827Supervised%20Learning.jpg)


![PIC](https://editor.analyticsvidhya.com/uploads/52149Unsupervised_Learning.png)

